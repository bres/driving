{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Επεξεργασία δεδομένων & δημιουργία Sliding Windows"
      ],
      "metadata": {
        "id": "liD40S7_DCo4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# CNN για εκτίμηση οδηγικής ασφάλειας με Grid Search & hold-out prediction\n",
        "\n",
        "# Εισαγωγή απαραίτητων βιβλιοθηκών\n",
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Βιβλιοθήκες PyTorch για τη δημιουργία και εκπαίδευση του νευρωνικού δικτύου\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "# Βιβλιοθήκες Scikit-learn για διαχωρισμό δεδομένων και αξιολόγηση\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder # Για κωδικοποίηση ετικετών (π.χ. 'safe' σε 0, 'risky' σε 1)\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "from itertools import product # Για τη δημιουργία συνδυασμών παραμέτρων για το Grid Search\n",
        "\n",
        "# === 1. Κλάση Επεξεργασίας Δεδομένων Επιτάχυνσης ===\n",
        "# Αυτή η κλάση είναι υπεύθυνη για την ανάγνωση, προ επεξεργασία και δημιουργία sliding windows (παραθύρων)\n",
        "# από τα δεδομένα επιτάχυνσης και τις αντίστοιχες ετικέτες.\n",
        "class DrivingDataProcessor:\n",
        "    # Ο κατασκευαστής της κλάσης\n",
        "    def __init__(self, csv_file):\n",
        "        # Έλεγχος αν υπάρχει το αρχείο δεδομένων επιτάχυνσης\n",
        "        if not os.path.exists(csv_file):\n",
        "            raise FileNotFoundError(f\"Δεν βρέθηκε το αρχείο δεδομένων: {csv_file}\")\n",
        "        self.df = pd.read_csv(csv_file) # Ανάγνωση του αρχείου σε DataFrame\n",
        "\n",
        "        # Έλεγχος αν υπάρχουν οι απαραίτητες στήλες στο αρχείο\n",
        "        required_columns = [\n",
        "            'Acceleration_X_Lateral',\n",
        "            'Acceleration_Y_Longitudinal',\n",
        "            'Acceleration_Z_Vertical',\n",
        "            'Global_Time_Seconds'\n",
        "        ]\n",
        "        if not all(col in self.df.columns for col in required_columns):\n",
        "            raise ValueError(f\"Το αρχείο πρέπει να περιέχει τις στήλες: {required_columns}\")\n",
        "\n",
        "        # Αρχικοποίηση LabelEncoder για την κωδικοποίηση των ετικετών.\n",
        "        # Ελέγχουμε αν υπάρχει ήδη η στήλη ετικετών στο αρχείο δεδομένων.\n",
        "        # Αν όχι, τη δημιουργούμε με κλάσεις [0, 1] (ασφαλές, επικίνδυνο).\n",
        "        self.label_encoder = LabelEncoder()\n",
        "        if 'Driving_Safety_Assessment' in self.df.columns:\n",
        "            self.df['label_encoded'] = self.label_encoder.fit_transform(\n",
        "                self.df['Driving_Safety_Assessment']\n",
        "            )\n",
        "        else:\n",
        "            self.label_encoder.fit([0, 1])\n",
        "\n",
        "    # Συνάρτηση για τη δημιουργία sliding windows (παραθύρων) από τα δεδομένα\n",
        "    # και τη συσχέτισή τους με τις ετικέτες από ένα ξεχωριστό αρχείο.\n",
        "    def create_sequences_with_labels(self, window_size, label_file):\n",
        "        # Έλεγχος αν υπάρχει το αρχείο ετικετών\n",
        "        if not os.path.exists(label_file):\n",
        "            raise FileNotFoundError(f\"Δεν βρέθηκε το αρχείο ετικετών: {label_file}\")\n",
        "\n",
        "        # Ανάγνωση των ετικετών από το αρχείο (υποθέτουμε ότι είναι σε μία στήλη χωρίς header)\n",
        "        labels = pd.read_csv(label_file, header=None).values.squeeze()\n",
        "        # Ταξινόμηση του DataFrame με βάση το χρόνο για να εξασφαλίσουμε τη χρονική σειρά\n",
        "        sorted_df = self.df.sort_values('Global_Time_Seconds')\n",
        "        # Επιλογή των στηλών επιτάχυνσης\n",
        "        acc_data = sorted_df[['Acceleration_X_Lateral',\n",
        "                              'Acceleration_Y_Longitudinal',\n",
        "                              'Acceleration_Z_Vertical']].values\n",
        "\n",
        "        # Έλεγχος αν υπάρχουν αρκετά δεδομένα για να δημιουργήσουμε τα παράθυρα\n",
        "        total_needed = window_size * len(labels)\n",
        "        if len(acc_data) < total_needed:\n",
        "            raise ValueError(\"Δεν υπάρχουν αρκετά δεδομένα για όλα τα παράθυρα.\")\n",
        "\n",
        "        # Δημιουργία των ακολουθιών (παραθύρων)\n",
        "        sequences = []\n",
        "        for i in range(len(labels)):\n",
        "            start = i * window_size # Υπολογισμός της αρχής του παραθύρου\n",
        "            end = start + window_size # Υπολογισμός του τέλους του παραθύρου\n",
        "            sequences.append(acc_data[start:end]) # Προσθήκη του παραθύρου στη λίστα\n",
        "\n",
        "        # Επιστροφή των ακολουθιών και των ετικετών (ως λίστα)\n",
        "        return sequences, labels.tolist()\n"
      ],
      "metadata": {
        "id": "auP8NTmpDESb"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Φόρτωση των δεδομένων σε batches & Προσθήκη θορύβου Jitter Guassian για Augmentation"
      ],
      "metadata": {
        "id": "dZzvE3gNDLgQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# === 2. Κλάση Dataset για PyTorch ===\n",
        "# Φόρτωση των δεδομένων σε batches για την εκπαίδευση του μοντέλου PyTorch.\n",
        "class SlidingWindowDataset(Dataset):\n",
        "    # Ο κατασκευαστής της κλάσης\n",
        "    def __init__(self, sequences, labels, augment=False):\n",
        "        self.sequences = np.array(sequences) # Μετατροπή των ακολουθιών σε NumPy array\n",
        "        self.labels = labels # Αποθήκευση των ετικετών\n",
        "        self.augment = augment # data augmentation\n",
        "\n",
        "    # Συνάρτηση που επιστρέφει το συνολικό αριθμό δειγμάτων στο dataset\n",
        "    def __len__(self):\n",
        "        return len(self.sequences)\n",
        "\n",
        "    # Επιστρέφει ένα δείγμα (παράθυρο) και την ετικέτα του με βάση τον δείκτη (idx)\n",
        "    def __getitem__(self, idx):\n",
        "        x = self.sequences[idx] # Επιλογή της ακολουθίας (παραθύρου)\n",
        "        y = self.labels[idx] # Επιλογή της αντίστοιχης ετικέτας\n",
        "        if self.augment:\n",
        "            # Προσθήκη τυχαίου θορύβου (data augmentation)\n",
        "            noise = np.random.normal(0, 0.01, x.shape)\n",
        "            x = x + noise\n",
        "        x = x.T  # Transpose για να ταιριάζει με την είσοδο του Conv1d (κανάλια, χρόνος)\n",
        "\n",
        "        return torch.FloatTensor(x), torch.LongTensor([y])"
      ],
      "metadata": {
        "id": "l5YxvpG1DMAq"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Ορισμός της αρχιτεκτονικής του Convolutional Neural Network (CNN)."
      ],
      "metadata": {
        "id": "Coy4dM5kDSN3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# === 3. CNN Μοντέλο ===\n",
        "# Ορισμός της αρχιτεκτονικής του Convolutional Neural Network (CNN).\n",
        "class SafeDrivingCNN(nn.Module):\n",
        "    # Ο κατασκευαστής του μοντέλου\n",
        "    def __init__(self, sequence_length=5000, num_classes=2, dropout=0.5):\n",
        "        super().__init__() # Κλήση του κατασκευαστή της κλάσης (nn.Module)\n",
        "        # Ορισμός των convolutional επιπέδων\n",
        "        self.conv = nn.Sequential(\n",
        "            # Πρώτο Conv1d επίπεδο: 3 κανάλια εισόδου, 32 κανάλια εξόδου, μέγεθος kernel 7\n",
        "            nn.Conv1d(3, 32, 7, padding=3), nn.BatchNorm1d(32), nn.ReLU(), nn.MaxPool1d(2),\n",
        "            # Δεύτερο Conv1d επίπεδο: 32 κανάλια εισόδου, 64 κανάλια εξόδου, μέγεθος kernel 5\n",
        "            nn.Conv1d(32, 64, 5, padding=2), nn.BatchNorm1d(64), nn.ReLU(), nn.MaxPool1d(2),\n",
        "            # Τρίτο Conv1d επίπεδο: 64 κανάλια εισόδου, 128 κανάλια εξόδου, μέγεθος kernel 3\n",
        "            nn.Conv1d(64, 128, 3, padding=1), nn.BatchNorm1d(128), nn.ReLU(), nn.MaxPool1d(2)\n",
        "        )\n",
        "        # Υπολογισμός του μεγέθους της εξόδου μετά τα convolutional και pooling επίπεδα\n",
        "        conv_out = 128 * (sequence_length // 8) # Το //8 προκύπτει από τα τρία MaxPool1d(2)\n",
        "\n",
        "        # Ορισμός των fully connected (πλήρως συνδεδεμένων) επιπέδων\n",
        "        self.fc = nn.Sequential(\n",
        "            # Πρώτο γραμμικό επίπεδο\n",
        "            nn.Linear(conv_out, 256), nn.ReLU(), nn.Dropout(dropout),\n",
        "            # Δεύτερο γραμμικό επίπεδο\n",
        "            nn.Linear(256, 64), nn.ReLU(), nn.Dropout(dropout),\n",
        "            # Τρίτο γραμμικό επίπεδο (επίπεδο εξόδου)\n",
        "            nn.Linear(64, num_classes)\n",
        "        )\n",
        "\n",
        "    # Συνάρτηση forward\n",
        "    def forward(self, x):\n",
        "        x = self.conv(x) # Πέρασμα από τα convolutional επίπεδα\n",
        "        x = x.view(x.size(0), -1) # \"Ίσιωμα\" της εξόδου για τα fully connected επίπεδα (Flatten)\n",
        "        return self.fc(x) # Πέρασμα από τα fully connected επίπεδα και επιστροφή της εξόδου"
      ],
      "metadata": {
        "id": "R8TiIducDS7t"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Εκπαίδευση με Grid Search"
      ],
      "metadata": {
        "id": "BNHyohYxDYr0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# === 4. Εκπαίδευση με Grid Search ===\n",
        "# Eύρεση του καλύτερου συνδυασμού υπερπαραμέτρων.\n",
        "def grid_search_train(csv_file, label_file, window_size=5000, batch_size=8, epochs=5, use_augmentation=True):\n",
        "    # Δημιουργία αντικειμένου επεξεργασίας δεδομένων\n",
        "    processor = DrivingDataProcessor(csv_file)\n",
        "    # Δημιουργία ακολουθιών και ετικετών από τα αρχεία\n",
        "    sequences, labels = processor.create_sequences_with_labels(window_size=window_size, label_file=label_file)\n",
        "\n",
        "    # Διαχωρισμός των δεδομένων σε training και testing sets\n",
        "    # stratify=labels εξασφαλίζει ότι η αναλογία των κλάσεων είναι ίδια σε train και test με 20% για το test set\n",
        "    train_X, test_X, train_y, test_y = train_test_split(\n",
        "        sequences, labels, test_size=0.2, stratify=labels, random_state=42) # random_state για αναπαραγωγιμότητα\n",
        "\n",
        "    # Δημιουργώ PyTorch Dataset και DataLoader\n",
        "    train_set = SlidingWindowDataset(train_X, train_y, augment=use_augmentation)\n",
        "    test_set = SlidingWindowDataset(test_X, test_y, augment=False) # Δεν κάνουμε augmentation στο test set\n",
        "    train_loader = DataLoader(train_set, batch_size=batch_size, shuffle=True) # shuffle=True για τυχαία σειρά στα training batches\n",
        "    test_loader = DataLoader(test_set, batch_size=batch_size) # Δεν χρειάζεται shuffle στο test loader\n",
        "\n",
        "    # Έλεγχος διαθέσιμης συσκευής (GPU ή CPU)\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    print(f\"\\nΧρήση συσκευής: {device}\")\n",
        "    print(f\"Χρήση Data Augmentation: {use_augmentation}\")\n",
        "\n",
        "    # Ορισμός των υπερπαραμέτρων που θα δοκιμάσουμε στο Grid Search\n",
        "    learning_rates = [1e-3, 1e-4]\n",
        "    weight_decays = [0, 1e-5]\n",
        "    dropouts = [0.3, 0.5]\n",
        "    # Δημιουργία όλων των πιθανών συνδυασμών των υπερπαραμέτρων\n",
        "    param_grid = list(product(learning_rates, weight_decays, dropouts))\n",
        "\n",
        "    # Αρχικοποίηση μεταβλητών για την παρακολούθηση του καλύτερου μοντέλου\n",
        "    best_acc = 0\n",
        "    best_model = None\n",
        "    best_config = None\n",
        "    best_true_labels = []\n",
        "    best_predictions = []\n",
        "\n",
        "    # Επανάληψη για κάθε συνδυασμό υπερπαραμέτρων\n",
        "    for i, (lr, wd, do) in enumerate(param_grid):\n",
        "        print(f\"\\nΠείραμα {i+1}/{len(param_grid)} | LR={lr}, WD={wd}, Dropout={do}\")\n",
        "        # Δημιουργία νέου μοντέλου για τον τρέχοντα συνδυασμό παραμέτρων\n",
        "        model = SafeDrivingCNN(sequence_length=window_size, num_classes=len(np.unique(labels)), dropout=do).to(device)\n",
        "        # Ορισμός του Optimizer (Adam)\n",
        "        optimizer = optim.Adam(model.parameters(), lr=lr, weight_decay=wd)\n",
        "        # Ορισμός της συνάρτησης απώλειας (Cross-Entropy Loss)\n",
        "        criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "        # Εκπαίδευση του μοντέλου για συγκεκριμένο αριθμό epochs\n",
        "        for epoch in range(epochs):\n",
        "            model.train() # Θέση του μοντέλου σε training mode\n",
        "            total_loss, correct, total = 0, 0, 0\n",
        "            # Επανάληψη σε batches από τα training data\n",
        "            for data, targets in train_loader:\n",
        "                data, targets = data.to(device), targets.squeeze().to(device) # Μεταφορά δεδομένων στη συσκευή (GPU/CPU)\n",
        "                optimizer.zero_grad() # Μηδενισμός των gradients\n",
        "                outputs = model(data) # Πρόβλεψη του μοντέλου (forward pass)\n",
        "                loss = criterion(outputs, targets) # Υπολογισμός της απώλειας\n",
        "                loss.backward() # Υπολογισμός των gradients (backward pass)\n",
        "                optimizer.step() # Ενημέρωση των βαρών του μοντέλου\n",
        "                total_loss += loss.item() # Προσθήκη της απώλειας του batch στη συνολική απώλεια\n",
        "                preds = outputs.argmax(1) # Λήψη της κλάσης με τη μεγαλύτερη πιθανότητα\n",
        "                correct += (preds == targets).sum().item() # Μέτρηση σωστών προβλέψεων\n",
        "                total += targets.size(0) # Μέτρηση συνολικών δειγμάτων στο batch\n",
        "            acc = correct / total # Υπολογισμός ακρίβειας στο training set\n",
        "            print(f\"Epoch {epoch+1}: Loss={total_loss:.4f} | Accuracy={acc:.2%}\")\n",
        "\n",
        "        # Αξιολόγηση του μοντέλου στο test set μετά από κάθε epoch\n",
        "        model.eval() # Θέση του μοντέλου σε evaluation mode\n",
        "        correct, total = 0, 0\n",
        "        current_true_labels = [] # Λίστα για τις πραγματικές ετικέτες του test set\n",
        "        current_predictions = [] # Λίστα για τις προβλέψεις του μοντέλου στο test set\n",
        "        with torch.no_grad(): # Απενεργοποίηση υπολογισμού gradients κατά την αξιολόγηση\n",
        "            # Επανάληψη σε batches από τα testing data\n",
        "            for data, targets in test_loader:\n",
        "                data, targets = data.to(device), targets.squeeze().to(device) # Μεταφορά δεδομένων στη συσκευή\n",
        "                preds = model(data).argmax(1) # Πρόβλεψη και λήψη της κλάσης\n",
        "                correct += (preds == targets).sum().item() # Μέτρηση σωστών προβλέψεων\n",
        "                total += targets.size(0) # Μέτρηση συνολικών δειγμάτων\n",
        "                current_true_labels.extend(targets.cpu().numpy()) # Αποθήκευση πραγματικών ετικετών\n",
        "                current_predictions.extend(preds.cpu().numpy()) # Αποθήκευση προβλέψεων\n",
        "\n",
        "        acc = correct / total # Υπολογισμός ακρίβειας στο test set\n",
        "        print(f\"Accuracy στο test set: {acc:.2%}\")\n",
        "\n",
        "        # Ποιό μοντέλο είναι το καλύτερο?\n",
        "        if acc > best_acc:\n",
        "            best_acc = acc # Καλύτερη ακρίβεια\n",
        "            best_model = model # Αποθήκευση του καλύτερου μοντέλου\n",
        "            best_config = (lr, wd, do) # Αποθήκευση της καλύτερης ρύθμισης υπερπαραμέτρων\n",
        "            best_true_labels = current_true_labels # Αποθήκευση των πραγματικών ετικετών για το καλύτερο μοντέλο\n",
        "            best_predictions = current_predictions # Αποθήκευση των προβλέψεων για το καλύτερο μοντέλο\n",
        "\n",
        "    # Εκτύπωση των αποτελεσμάτων του Grid Search\n",
        "    print(f\"\\nΚαλύτερο config: LR={best_config[0]}, WD={best_config[1]}, Dropout={best_config[2]}\")\n",
        "    print(f\"Best Test Accuracy: {best_acc:.2%}\\n\")\n",
        "\n",
        "    # Αναφορά ταξινόμησης (Classification Report) για το καλύτερο μοντέλο\n",
        "    print(\"Classification Report (Test Set):\")\n",
        "    # Μετατροπή των ονομάτων των κλάσεων σε strings για την αναφορά\n",
        "    target_names = [str(c) for c in processor.label_encoder.classes_]\n",
        "    print(classification_report(best_true_labels, best_predictions, target_names=target_names))\n",
        "\n",
        "    # Confusion Matrix μόνο για το καλύτερο μοντέλο\n",
        "    cm = confusion_matrix(best_true_labels, best_predictions)\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
        "                xticklabels=target_names, yticklabels=target_names)\n",
        "    plt.title('Confusion Matrix - Test Set (Best Model)')\n",
        "    plt.xlabel('Predicted')\n",
        "    plt.ylabel('Actual')\n",
        "    plt.tight_layout()\n",
        "    plt.savefig('confusion_matrix_test_set.png', dpi=300)\n",
        "    plt.close()\n",
        "    print(\"Confusion Matrix αποθηκεύτηκε ως confusion_matrix_test_set.png\")\n",
        "\n",
        "    # Επιστροφή του καλύτερου μοντέλου και του processor\n",
        "    return best_model, processor\n"
      ],
      "metadata": {
        "id": "70Vo17NEDZWm"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Πρόβλεψη σε hold-out δεδομένα (10%) μη χρησιμοποιημένο"
      ],
      "metadata": {
        "id": "4zggzTDhDdRL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# === 5. Πρόβλεψη σε hold-out δεδομένα ===\n",
        "# Πρόβλεψη σε ένα ξεχωριστό set δεδομένων (hold-out).\n",
        "# 10% των συνολικών αρχικών δεδομένων) είναι ένα ξεχωριστό σύνολο δεδομένων που δε χρησιμοποιήθηκε καθόλου κατά τη διάρκεια\n",
        "# του Grid Search (ούτε για training ούτε για testing)\n",
        "def predict_with_sliding_windows(model, processor, new_data, window_size=5000):\n",
        "    model.eval() # Θέση του μοντέλου σε evaluation mode\n",
        "    device = next(model.parameters()).device # Εύρεση της συσκευής που χρησιμοποιεί το μοντέλο\n",
        "    # Επιλογή των στηλών επιτάχυνσης από τα νέα δεδομένα\n",
        "    acc_data = new_data[['Acceleration_X_Lateral','Acceleration_Y_Longitudinal','Acceleration_Z_Vertical']].values\n",
        "    predictions = [] # Λίστα για να αποθηκεύσουμε τις πιθανότητες πρόβλεψης για κάθε παράθυρο\n",
        "\n",
        "    for start in range(0, len(acc_data) - window_size + 1, window_size):\n",
        "        window = acc_data[start:start + window_size]\n",
        "        tensor = torch.FloatTensor(window.T).unsqueeze(0).to(device) # .T για σωστή διάσταση, .unsqueeze(0) για batch dimension\n",
        "        with torch.no_grad(): # Απενεργοποίηση υπολογισμού gradients\n",
        "            output = model(tensor)\n",
        "            # Υπολογισμός πιθανοτήτων με softmax\n",
        "            prob = torch.softmax(output, dim=1).cpu().numpy()[0]\n",
        "            predictions.append(prob) # Αποθήκευση των πιθανοτήτων του παραθύρου\n",
        "\n",
        "    # Υπολογισμός της μέσης πιθανότητας για όλες τις κλάσες σε όλα τα παράθυρα\n",
        "    avg_probs = np.mean(predictions, axis=0)\n",
        "    # Επιλογή της κλάσης με τη μεγαλύτερη μέση πιθανότητα ως τελική πρόβλεψη\n",
        "    predicted_class = int(np.argmax(avg_probs))\n",
        "    # Αποκωδικοποίηση της κλάσης στην αρχική της μορφή (π.χ. 0 -> 'safe')\n",
        "    decoded_label = processor.label_encoder.inverse_transform([predicted_class])[0]\n",
        "    # Mέγιστη μέση πιθανότητα ως εμπιστοσύνη στην πρόβλεψη\n",
        "    confidence = float(np.max(avg_probs))\n",
        "\n",
        "    # Εκτύπωση πρόβλεψης\n",
        "    print(f\"\\nΤελική πρόβλεψη: {decoded_label} με εμπιστοσύνη {confidence:.2%}\")\n",
        "    # Επιστροφή της προβλεπόμενης κλάσης, της αποκωδικοποιημένης ετικέτας, της εμπιστοσύνης και των πιθανοτήτων ανά παράθυρο\n",
        "    return predicted_class, decoded_label, confidence, predictions"
      ],
      "metadata": {
        "id": "BJtQ-m34DdnB"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Αυστηρή απόφαση κινδύνου, ενα παράθυρο risky ισοδυναμεί με όλη η διαδρομή risky"
      ],
      "metadata": {
        "id": "BboGYGa_DhLA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# === 6. Αυστηρή απόφαση κινδύνου ===\n",
        "# Συνάρτηση που λαμβάνει μια πιο \"αυστηρή\" απόφαση για όλη τη διαδρομή\n",
        "# με βάση τις προβλέψεις ανά παράθυρο.\n",
        "def strict_risk_decision(predictions, processor, risk_threshold=0.5):\n",
        "    # Μετράμε πόσα παράθυρα χαρακτηρίστηκαν ως 'risky' (κλάση 1) με πιθανότητα > risk_threshold\n",
        "    risky_windows = sum(1 for p in predictions if p[1] > risk_threshold)\n",
        "    total_windows = len(predictions) # Συνολικός αριθμός παραθύρων\n",
        "\n",
        "    # Αν δεν υπάρχουν παράθυρα, επιστρέφουμε 'safe' με 0 εμπιστοσύνη\n",
        "    if total_windows == 0:\n",
        "        return 0, processor.label_encoder.inverse_transform([0])[0], 0.0\n",
        "\n",
        "    # Υπολογισμός της αναλογίας των 'risky' παραθύρων\n",
        "    risky_ratio = risky_windows / total_windows\n",
        "\n",
        "    # Αν υπάρχει έστω και ένα 'risky' παράθυρο, θεωρούμε όλη τη διαδρομή 'risky'\n",
        "    if risky_ratio > 0:\n",
        "        predicted_class = 1 # Η κλάση είναι 1 (risky)\n",
        "        confidence = risky_ratio # Η εμπιστοσύνη είναι η αναλογία των risky παραθύρων\n",
        "    else:\n",
        "        # Αν δεν υπάρχει κανένα 'risky' παράθυρο, θεωρούμε τη διαδρομή 'safe'\n",
        "        predicted_class = 0 # Η κλάση είναι 0 (safe)\n",
        "        confidence = 1.0 # Η εμπιστοσύνη στη 'safe' κλάση είναι υψηλή (100%)\n",
        "\n",
        "    # Αποκωδικοποίηση της τελικής κλάσης\n",
        "    decoded_label = processor.label_encoder.inverse_transform([predicted_class])[0]\n",
        "    # Επιστροφή της τελικής κλάσης, της ετικέτας και της εμπιστοσύνης\n",
        "    return predicted_class, decoded_label, confidence"
      ],
      "metadata": {
        "id": "Gpl0YlbPDhp2"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Εκτέλεση του κυρίως προγράμματος"
      ],
      "metadata": {
        "id": "QLU_ANABDl_B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# === 7. Εκτέλεση του κυρίως προγράμματος ===\n",
        "if __name__ == \"__main__\":\n",
        "    # Ορισμός των αρχείων και των βασικών παραμέτρων\n",
        "    csv_file = \"acceleration_data.csv\" # Αρχείο με δεδομένα επιτάχυνσης\n",
        "    label_file = \"empirical_labels.csv\" # Αρχείο με ετικέτες (0 ή 1)\n",
        "    window_size = 5000 # Μέγεθος του συρόμενου παραθύρου (σε δείγματα)\n",
        "    batch_size = 8 # Μέγεθος batch για την εκπαίδευση\n",
        "    epochs = 5 # Αριθμός epochs για την εκπαίδευση κάθε μοντέλου στο grid search\n",
        "\n",
        "    # === Εκπαίδευση με Grid Search ===\n",
        "    # Καλούμε τη συνάρτηση grid_search_train για να εκπαιδεύσουμε το μοντέλο με Grid Search\n",
        "    # και να βρούμε τις καλύτερες υπερπαραμέτρους. use_augmentation είναι False σε αυτή την περίπτωση.\n",
        "    model, processor = grid_search_train(\n",
        "        csv_file=csv_file,\n",
        "        label_file=label_file,\n",
        "        window_size=window_size,\n",
        "        batch_size=batch_size,\n",
        "        epochs=epochs,\n",
        "        use_augmentation=True # Δεν χρησιμοποιούμε data augmentation σε αυτό το run-αλλάζει την default επιλογή\n",
        "    )\n",
        "\n",
        "    # === Δημιουργία hold-out set ===\n",
        "    # Ξαναδημιουργούμε όλες τις ακολουθίες και ετικέτες για να πάρουμε ένα ξεχωριστό hold-out set\n",
        "    # που δεν χρησιμοποιήθηκε καθόλου στην εκπαίδευση ή την αξιολόγηση του grid search.\n",
        "    all_sequences, all_labels = processor.create_sequences_with_labels(window_size, label_file)\n",
        "    total_windows = len(all_sequences) # Συνολικός αριθμός παραθύρων στα αρχικά δεδομένα\n",
        "    # Διαχωρισμός για τη δημιουργία του hold-out set (10% των συνολικών παραθύρων)\n",
        "    _, test_X, _, test_y = train_test_split(\n",
        "        all_sequences, all_labels, test_size=0.1, stratify=all_labels, random_state=42\n",
        "    )\n",
        "\n",
        "    # === Εκτυπώσεις ===\n",
        "    holdout_windows = len(test_X)\n",
        "    print(f\"\\nΣυνολικά παράθυρα: {total_windows}\")\n",
        "    print(f\"Παράθυρα στο hold-out set: {holdout_windows}\")\n",
        "    print(f\"Χρονική διάρκεια κάθε παραθύρου: {window_size} δείγματα\")\n",
        "    print(f\"Συνολική διάρκεια hold-out: {holdout_windows * window_size} δείγματα\")\n",
        "\n",
        "    # === Προετοιμασία hold-out dataframe ===\n",
        "    df_holdout = pd.DataFrame(np.concatenate(test_X), columns=[\n",
        "        \"Acceleration_X_Lateral\", \"Acceleration_Y_Longitudinal\", \"Acceleration_Z_Vertical\"\n",
        "    ])\n",
        "\n",
        "    # === Πρόβλεψη στο hold-out ===\n",
        "    # Καλούμε τη συνάρτηση predict_with_sliding_windows για να κάνουμε προβλέψεις\n",
        "    # στο hold-out set χρησιμοποιώντας το καλύτερο μοντέλο από το grid search.\n",
        "    predicted_class, decoded_label, confidence, predictions = predict_with_sliding_windows(\n",
        "        model, processor, df_holdout, window_size=window_size\n",
        "    )\n",
        "\n",
        "    # === Αυστηρή απόφαση ===\n",
        "    # Καλούμε τη συνάρτηση strict_risk_decision για να πάρουμε τη \"αυστηρή\" τελική απόφαση\n",
        "    # για όλη τη διαδρομή του hold-out set.\n",
        "    strict_class, strict_label, strict_conf = strict_risk_decision(predictions, processor)\n",
        "    print(f\"\\nΑυστηρή απόφαση: {strict_label} με εμπιστοσύνη {strict_conf:.2%}\")\n",
        "\n",
        "    # === Γράφημα πιθανότητας 'risky' ανά παράθυρο ===\n",
        "    # Δημιουργία γραφήματος που δείχνει την πιθανότητα η κάθε παράθυρο να είναι 'risky'\n",
        "    risky_probs = [p[1] for p in predictions] # Λήψη των πιθανοτήτων για την κλάση 'risky' (κλάση 1)\n",
        "    plt.figure(figsize=(10, 4))\n",
        "    plt.plot(range(len(risky_probs)), risky_probs, marker='o', color='blue', label='P(risky)')\n",
        "    plt.axhline(0.5, color='gray', linestyle='--', label='Κατώφλι 50%') # Οριζόντια γραμμή στο 50%\n",
        "    plt.title(\"Πιθανότητα 'risky' ανά παράθυρο (Hold-out)\")\n",
        "    plt.xlabel(\"Αριθμός παραθύρου\")\n",
        "    plt.ylabel(\"P(risky)\")\n",
        "    plt.grid(True)\n",
        "    plt.legend()\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(\"risky_per_window_holdout.png\", dpi=300) # Αποθήκευση του γραφήματος\n",
        "    plt.close() # Κλείσιμο της φιγούρας\n",
        "    print(\"Αποθηκεύτηκε ως risky_per_window_holdout.png\")\n",
        "\n",
        "    # === Μέση πιθανότητα 'risky' ===\n",
        "    # Δημιουργία γραφήματος που δείχνει τη μέση πιθανότητα να είναι 'risky' για όλο το hold-out set\n",
        "    mean_risky = np.mean(risky_probs) # Υπολογισμός της μέσης πιθανότητας 'risky'\n",
        "    plt.figure(figsize=(6, 4))\n",
        "    # Δημιουργία μπάρας, χρώμα κόκκινο αν η μέση πιθανότητα > 0.5, πράσινο αλλιώς\n",
        "    plt.bar([\"Μέση πιθανότητα 'risky'\"], [mean_risky], color='red' if mean_risky > 0.5 else 'green')\n",
        "    plt.axhline(0.5, color='gray', linestyle='--', label='Κατώφλι 50%') # Οριζόντια γραμμή στο 50%\n",
        "    plt.ylim(0, 1) # Ορισμός ορίων στον άξονα y από 0 έως 1\n",
        "    plt.title(\"Μέση εκτίμηση διαδρομής (Hold-out Set)\")\n",
        "    plt.ylabel(\"Πιθανότητα 'risky'\")\n",
        "    plt.legend() # Εμφάνιση λεζάντας\n",
        "    plt.tight_layout() # Προσαρμογή διάταξης\n",
        "    plt.savefig(\"inference_mean_risk.png\", dpi=300) # Αποθήκευση του γραφήματος\n",
        "    plt.close() # Κλείσιμο της φιγούρας\n",
        "    print(\"Η μέση εκτίμηση αποθηκεύτηκε ως inference_mean_risk.png\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qpdh9eT0Dmbv",
        "outputId": "54c8da35-afa5-4812-85d7-441c91a38562"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Χρήση συσκευής: cpu\n",
            "Χρήση Data Augmentation: True\n",
            "\n",
            "Πείραμα 1/8 | LR=0.001, WD=0, Dropout=0.3\n",
            "Epoch 1: Loss=40.1348 | Accuracy=73.04%\n",
            "Epoch 2: Loss=31.2174 | Accuracy=83.48%\n",
            "Epoch 3: Loss=32.7722 | Accuracy=72.17%\n",
            "Epoch 4: Loss=7.2870 | Accuracy=82.61%\n",
            "Epoch 5: Loss=7.6114 | Accuracy=75.65%\n",
            "Accuracy στο test set: 89.66%\n",
            "\n",
            "Πείραμα 2/8 | LR=0.001, WD=0, Dropout=0.5\n",
            "Epoch 1: Loss=96.5982 | Accuracy=67.83%\n",
            "Epoch 2: Loss=48.2134 | Accuracy=81.74%\n",
            "Epoch 3: Loss=34.2309 | Accuracy=76.52%\n",
            "Epoch 4: Loss=20.4724 | Accuracy=87.83%\n",
            "Epoch 5: Loss=23.6794 | Accuracy=81.74%\n",
            "Accuracy στο test set: 68.97%\n",
            "\n",
            "Πείραμα 3/8 | LR=0.001, WD=1e-05, Dropout=0.3\n",
            "Epoch 1: Loss=44.4138 | Accuracy=81.74%\n",
            "Epoch 2: Loss=55.0687 | Accuracy=72.17%\n",
            "Epoch 3: Loss=17.5673 | Accuracy=73.91%\n",
            "Epoch 4: Loss=13.0256 | Accuracy=83.48%\n",
            "Epoch 5: Loss=4.0325 | Accuracy=87.83%\n",
            "Accuracy στο test set: 89.66%\n",
            "\n",
            "Πείραμα 4/8 | LR=0.001, WD=1e-05, Dropout=0.5\n",
            "Epoch 1: Loss=86.8945 | Accuracy=76.52%\n",
            "Epoch 2: Loss=65.7482 | Accuracy=77.39%\n",
            "Epoch 3: Loss=25.6377 | Accuracy=78.26%\n",
            "Epoch 4: Loss=27.3713 | Accuracy=73.91%\n",
            "Epoch 5: Loss=12.0773 | Accuracy=80.00%\n",
            "Accuracy στο test set: 89.66%\n",
            "\n",
            "Πείραμα 5/8 | LR=0.0001, WD=0, Dropout=0.3\n",
            "Epoch 1: Loss=9.1425 | Accuracy=78.26%\n",
            "Epoch 2: Loss=6.3582 | Accuracy=82.61%\n",
            "Epoch 3: Loss=5.5785 | Accuracy=86.09%\n",
            "Epoch 4: Loss=5.7350 | Accuracy=86.96%\n",
            "Epoch 5: Loss=4.1722 | Accuracy=87.83%\n",
            "Accuracy στο test set: 89.66%\n",
            "\n",
            "Πείραμα 6/8 | LR=0.0001, WD=0, Dropout=0.5\n",
            "Epoch 1: Loss=11.1604 | Accuracy=75.65%\n",
            "Epoch 2: Loss=16.3811 | Accuracy=80.00%\n",
            "Epoch 3: Loss=8.1950 | Accuracy=84.35%\n",
            "Epoch 4: Loss=13.0844 | Accuracy=82.61%\n",
            "Epoch 5: Loss=10.9496 | Accuracy=75.65%\n",
            "Accuracy στο test set: 89.66%\n",
            "\n",
            "Πείραμα 7/8 | LR=0.0001, WD=1e-05, Dropout=0.3\n",
            "Epoch 1: Loss=8.8381 | Accuracy=78.26%\n",
            "Epoch 2: Loss=6.1072 | Accuracy=87.83%\n",
            "Epoch 3: Loss=13.7396 | Accuracy=81.74%\n",
            "Epoch 4: Loss=5.1388 | Accuracy=87.83%\n",
            "Epoch 5: Loss=7.9585 | Accuracy=80.87%\n",
            "Accuracy στο test set: 82.76%\n",
            "\n",
            "Πείραμα 8/8 | LR=0.0001, WD=1e-05, Dropout=0.5\n",
            "Epoch 1: Loss=13.9054 | Accuracy=73.91%\n",
            "Epoch 2: Loss=13.9811 | Accuracy=83.48%\n",
            "Epoch 3: Loss=12.7094 | Accuracy=80.87%\n",
            "Epoch 4: Loss=14.7206 | Accuracy=75.65%\n",
            "Epoch 5: Loss=8.0921 | Accuracy=87.83%\n",
            "Accuracy στο test set: 93.10%\n",
            "\n",
            "Καλύτερο config: LR=0.0001, WD=1e-05, Dropout=0.5\n",
            "Best Test Accuracy: 93.10%\n",
            "\n",
            "Classification Report (Test Set):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.91      1.00      0.95        20\n",
            "           1       1.00      0.78      0.88         9\n",
            "\n",
            "    accuracy                           0.93        29\n",
            "   macro avg       0.95      0.89      0.91        29\n",
            "weighted avg       0.94      0.93      0.93        29\n",
            "\n",
            "Confusion Matrix αποθηκεύτηκε ως confusion_matrix_test_set.png\n",
            "\n",
            "Συνολικά παράθυρα: 144\n",
            "Παράθυρα στο hold-out set: 15\n",
            "Χρονική διάρκεια κάθε παραθύρου: 5000 δείγματα\n",
            "Συνολική διάρκεια hold-out: 75000 δείγματα\n",
            "\n",
            "Τελική πρόβλεψη: 0 με εμπιστοσύνη 67.12%\n",
            "\n",
            "Αυστηρή απόφαση: 1 με εμπιστοσύνη 26.67%\n",
            "Αποθηκεύτηκε ως risky_per_window_holdout.png\n",
            "Η μέση εκτίμηση αποθηκεύτηκε ως inference_mean_risk.png\n"
          ]
        }
      ]
    }
  ]
}